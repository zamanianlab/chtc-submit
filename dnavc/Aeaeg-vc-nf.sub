# Input data: /staging/groups/zamanian_group/input/$(dir).tar
# Run: condor_submit Aeaeg-vc-nf.sub dir=220223_BH7NGKDSX3_sub

# request Zamanian Lab server
Accounting_Group = PathobiologicalSciences_Zamanian

# load docker image; request execute server with large data staging
universe = docker
docker_image = zamanianlab/chtc-dnavc:v1
Requirements = (Target.HasCHTCStaging == true) && \
               (OpSysMajorVer == 7) || (OpSysMajorVer == 8)

# executable (/home/{net-id}/) and arguments
executable = Aeaeg-vc-nf.sh
arguments = $(dir)

# log, error, and output files
log = $(dir)_$(Cluster)_$(Process).log
error = $(dir)_$(Cluster)_$(Process).err
output = $(dir)_$(Cluster)_$(Process).out

# transfer files in-out of /home/{net-id}/
transfer_input_files =
should_transfer_files = YES
when_to_transfer_output = ON_EXIT

# memory, disk and CPU requests
request_cpus = 40
request_memory = 256GB
request_disk = 1500GB

# for jobs > 72 hours
+LongJob = true

# submit 1 job
queue 1
### END
