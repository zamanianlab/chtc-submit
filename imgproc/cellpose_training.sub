# request Zamanian Lab server
Accounting_Group = PathobiologicalSciences_Zamanian

# load docker image; request execute server with large data staging
universe = docker
docker_image = zamanianlab/chtc-wrmxpress:v3
Requirements = (Target.HasCHTCStaging == true)

# executable (/home/{net-id}/) and arguments
executable = $(script)

# log, error, and output files
log = $(plate)_$(Cluster)_$(Process).log
error = $(plate)_$(Cluster)_$(Process).err
output = $(plate)_$(Cluster)_$(Process).out

# transfer files in-out of /home/{net-id}/
transfer_input_files = $(plate).yml
should_transfer_files = YES
when_to_transfer_output = ON_EXIT

# memory, disk, GPU, and CPU requests
# GPU info https://chtc.cs.wisc.edu/uw-research-computing/gpu-jobs.html
request_cpus = 16
request_memory = 50GB
request_disk = 100GB

request_gpus = 1
+WantGPULab = true
+GPUJobLength = "medium" 

# submit a job for each directory in dir_list.txt
queue 1
### END
